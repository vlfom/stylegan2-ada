{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UDVO2FGKIQw"
   },
   "source": [
    "# StyleGAN2-ADA: training a model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruo5KFL4yw0j"
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_location = '/content/drive/MyDrive/Work/Regular/Unetiq/ARNO/datasets/Bonn/filtered_128_50k.zip'\n",
    "tf_data_location = '/content/drive/MyDrive/Work/Regular/Unetiq/ARNO/datasets/Bonn/tf_data/tf-dataset-bonn-labeled.zip'\n",
    "# tf_data_location = '/content/drive/MyDrive/Work/Regular/Unetiq/ARNO/datasets/Bonn/tf_data/tf-dataset-bonn-256-labeled.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "56Vt8uJ9I78P"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "# # Unzip from Google Drive\n",
    "\n",
    "# %cd /content\n",
    "# !cp {zip_location} /content/\n",
    "# !unzip /content/filtered_128_50k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process\n",
    "\n",
    "# %cd /content\n",
    "# !python stylegan2-ada/dataset_tool.py create_from_images /content/datasets/bonn /content/filtered_128/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Upload generated results to GDrive\n",
    "\n",
    "# %cd /content/datasets\n",
    "# !zip -r tf-dataset-bonn-labeled.zip bonn\n",
    "# !cp /content/datasets/tf-dataset-bonn-labeled.zip {tf_data_location}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from GDrive directly\n",
    "\n",
    "!mkdir /content/datasets\n",
    "!cp {tf_data_location} /content/datasets/\n",
    "%cd /content/datasets\n",
    "!unzip /content/datasets/tf-dataset-bonn-labeled.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to delete labels from the folders if training an unconditional one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWpIjP7hKzJZ"
   },
   "source": [
    "## Train new networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure ClearML\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CLEARML_PROJECT_NAME\"] = \"Unetiq-ARNO\"\n",
    "os.environ[\"CLEARML_TASK_NAME\"] = \"StyleGAN2-ada-128x-v0\"\n",
    "\n",
    "# Set ClearML parameters\n",
    "\n",
    "from clearml import Task, Logger\n",
    "\n",
    "task = Task.init(project_name=os.environ[\"CLEARML_PROJECT_NAME\"], task_name=os.environ[\"CLEARML_TASK_NAME\"], continue_last_task=True)\n",
    "task.connect_configuration('/root/clearml.conf')\n",
    "logger = task.get_logger()\n",
    "logger.set_default_upload_destination(uri='gs://clearml-bucket-0')\n",
    "\n",
    "parameters = {\n",
    "    'model': 'stylegan2-ada',\n",
    "    'type':  'uncond',\n",
    "    'data':  'bonn-128-50k'\n",
    "}\n",
    "\n",
    "parameters = task.connect(parameters)\n",
    "\n",
    "task.mark_stopped()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CLEARML_PROJECT_NAME\"] = \"Unetiq-ARNO\"\n",
    "os.environ[\"CLEARML_TASK_NAME\"] = \"StyleGAN2-ada-128x-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to Tensorflow 1.x\n",
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "f8TWmeqExkda",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "ClearML Task: continuing previous task id=054825127b064dd6b770fd3864d1e6a3 Notice this run will not be reproducible!\n",
      "ClearML results page: https://app.community.clear.ml/projects/945bd0c36255401197336ac56f0c2cc3/experiments/054825127b064dd6b770fd3864d1e6a3/output/log\n",
      "tcmalloc: large alloc 4294967296 bytes == 0x7ab8000 @  0x7fb61ab00001 0x7fb617d434ff 0x7fb617d93b08 0x7fb617d97ac7 0x7fb617e361a3 0x50a4a5 0x50cc96 0x507be4 0x508ec2 0x594a01 0x549e8f 0x5515c1 0x5a9dac 0x50a433 0x50cc96 0x507be4 0x588e5c 0x59fd0e 0x50d256 0x507be4 0x588e5c 0x59fd0e 0x50d256 0x507be4 0x588e5c 0x59fd0e 0x50d256 0x5095c8 0x50a2fd 0x50beb4 0x507be4\n",
      "tcmalloc: large alloc 4294967296 bytes == 0x7fb429420000 @  0x7fb61aafe1e7 0x7fb617d4341e 0x7fb617d93c2b 0x7fb617d9430f 0x7fb617e360a3 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4\n",
      "tcmalloc: large alloc 4294967296 bytes == 0x7fb32841e000 @  0x7fb61aafe1e7 0x7fb617d4341e 0x7fb617d93c2b 0x7fb617d9430f 0x7fb5c36830c5 0x7fb5c3006902 0x7fb5c3006eb2 0x7fb5c2fbfc3e 0x50a12f 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x588c8b 0x59fd0e 0x50d256 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x508ec2 0x594a01\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 1\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1\n",
      "    }\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 10,\n",
      "  \"network_snapshot_ticks\": 30,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"/content/datasets/bonn\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": true\n",
      "  },\n",
      "  \"metric_arg_list\": [],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"/content/datasets/bonn\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": true\n",
      "  },\n",
      "  \"total_kimg\": 50000,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": 0.05,\n",
      "  \"run_dir\": \"/content/saves/00000-bonn-mirror-auto_tuned1-kimg50000\"\n",
      "}\n",
      "\n",
      "Output directory:  /content/saves/00000-bonn-mirror-auto_tuned1-kimg50000\n",
      "Training data:     /content/datasets/bonn\n",
      "Training length:   50000 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "tcmalloc: large alloc 4294967296 bytes == 0x7ab8000 @  0x7fb61ab00001 0x7fb617d434ff 0x7fb617d93b08 0x7fb617d97ac7 0x7fb617e361a3 0x50a4a5 0x50cc96 0x507be4 0x508ec2 0x594a01 0x549e8f 0x5515c1 0x5a9dac 0x50a433 0x50cc96 0x507be4 0x588e5c 0x59fd0e 0x50d256 0x507be4 0x588e5c 0x59fd0e 0x50d256 0x507be4 0x588e5c 0x59fd0e 0x50d256 0x5095c8 0x50a2fd 0x50beb4 0x507be4\n",
      "tcmalloc: large alloc 4294967296 bytes == 0x7fb21a2b2000 @  0x7fb61aafe1e7 0x7fb617d4341e 0x7fb617d93c2b 0x7fb617d9430f 0x7fb617e360a3 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4\n",
      "tcmalloc: large alloc 4294967296 bytes == 0x7fb21a2b2000 @  0x7fb61aafe1e7 0x7fb617d4341e 0x7fb617d93c2b 0x7fb617d9430f 0x7fb5c36830c5 0x7fb5c3006902 0x7fb5c3006eb2 0x7fb5c2fbfc3e 0x50a12f 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x588c8b 0x59fd0e 0x50d256 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x508ec2 0x594a01\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23882369                                      \n",
      "\n",
      "Exporting sample images...\n",
      "2021-01-25 23:26:58.461253: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 50331648 exceeds 10% of system memory.\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 50000 kimg...\n",
      "\n",
      "tick 0     kimg 0.1      time 1m 48s       sec/tick 14.9    sec/kimg 116.66  maintenance 93.0   gpumem 8.6   augment 0.000\n",
      "tick 1     kimg 4.2      time 3m 08s       sec/tick 57.9    sec/kimg 14.15   maintenance 22.3   gpumem 8.6   augment 0.006\n",
      "tick 2     kimg 8.3      time 4m 06s       sec/tick 57.8    sec/kimg 14.11   maintenance 0.0    gpumem 8.6   augment 0.012\n",
      "tick 3     kimg 12.4     time 5m 04s       sec/tick 57.8    sec/kimg 14.12   maintenance 0.0    gpumem 8.6   augment 0.016\n",
      "tick 4     kimg 16.5     time 6m 02s       sec/tick 58.0    sec/kimg 14.15   maintenance 0.0    gpumem 8.6   augment 0.022\n",
      "tick 5     kimg 20.6     time 7m 00s       sec/tick 57.9    sec/kimg 14.14   maintenance 0.0    gpumem 8.6   augment 0.027\n",
      "tick 6     kimg 24.7     time 7m 58s       sec/tick 58.1    sec/kimg 14.18   maintenance 0.0    gpumem 8.6   augment 0.031\n",
      "tick 7     kimg 28.8     time 8m 56s       sec/tick 58.0    sec/kimg 14.17   maintenance 0.0    gpumem 8.6   augment 0.038\n",
      "tick 8     kimg 32.9     time 9m 54s       sec/tick 58.0    sec/kimg 14.17   maintenance 0.0    gpumem 8.6   augment 0.043\n",
      "tick 9     kimg 37.0     time 10m 52s      sec/tick 58.1    sec/kimg 14.17   maintenance 0.0    gpumem 8.6   augment 0.047\n",
      "tick 10    kimg 41.1     time 11m 50s      sec/tick 58.1    sec/kimg 14.18   maintenance 0.0    gpumem 8.6   augment 0.053\n",
      "tick 11    kimg 45.2     time 12m 55s      sec/tick 58.1    sec/kimg 14.20   maintenance 6.5    gpumem 8.6   augment 0.059\n",
      "tick 12    kimg 49.3     time 13m 53s      sec/tick 58.0    sec/kimg 14.15   maintenance 0.0    gpumem 8.6   augment 0.063\n",
      "tick 13    kimg 53.4     time 14m 51s      sec/tick 58.1    sec/kimg 14.18   maintenance 0.0    gpumem 8.6   augment 0.068\n",
      "tick 14    kimg 57.5     time 15m 49s      sec/tick 58.1    sec/kimg 14.19   maintenance 0.0    gpumem 8.6   augment 0.072\n",
      "tick 15    kimg 61.6     time 16m 47s      sec/tick 58.0    sec/kimg 14.16   maintenance 0.0    gpumem 8.6   augment 0.077\n",
      "tick 16    kimg 65.7     time 17m 45s      sec/tick 58.1    sec/kimg 14.17   maintenance 0.0    gpumem 8.6   augment 0.078\n",
      "tick 17    kimg 69.8     time 18m 43s      sec/tick 58.2    sec/kimg 14.20   maintenance 0.0    gpumem 8.6   augment 0.080\n",
      "tick 18    kimg 73.9     time 19m 41s      sec/tick 58.0    sec/kimg 14.16   maintenance 0.0    gpumem 8.6   augment 0.083\n",
      "tick 19    kimg 78.0     time 20m 39s      sec/tick 58.2    sec/kimg 14.20   maintenance 0.0    gpumem 8.6   augment 0.086\n",
      "tick 20    kimg 82.0     time 21m 38s      sec/tick 58.3    sec/kimg 14.22   maintenance 0.0    gpumem 8.6   augment 0.085\n",
      "tick 21    kimg 86.1     time 22m 45s      sec/tick 58.1    sec/kimg 14.19   maintenance 9.2    gpumem 8.6   augment 0.084\n",
      "tick 22    kimg 90.2     time 23m 43s      sec/tick 58.3    sec/kimg 14.23   maintenance 0.0    gpumem 8.6   augment 0.084\n",
      "tick 23    kimg 94.3     time 24m 41s      sec/tick 58.2    sec/kimg 14.21   maintenance 0.0    gpumem 8.6   augment 0.084\n",
      "tick 24    kimg 98.4     time 25m 40s      sec/tick 58.2    sec/kimg 14.20   maintenance 0.0    gpumem 8.6   augment 0.085\n",
      "tick 25    kimg 102.5    time 26m 38s      sec/tick 58.2    sec/kimg 14.22   maintenance 0.0    gpumem 8.6   augment 0.088\n"
     ]
    }
   ],
   "source": [
    "# %cd /content\n",
    "# !python stylegan2-ada/train.py \\\n",
    "#  --outdir='/content/saves' \\\n",
    "#  --snap=30 \\\n",
    "#  --im_snap=10 \\\n",
    "#  --gpus=1 \\\n",
    "#  --data='/content/datasets/bonn' \\\n",
    "#  --mirror=true \\\n",
    "#  --metrics=none \\\n",
    "#  --kimg=50000 \\\n",
    "#  --cfg=auto_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FGozskE2gGM"
   },
   "source": [
    "#### Resume from latest snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7s7cdAcU2l3x",
    "outputId": "3576be3f-da00-44c3-d19c-6e9c98f7f8b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "ClearML Task: continuing previous task id=d1d9013b6cd64401899d4b49e2d50e8c Notice this run will not be reproducible!\n",
      "ClearML results page: https://app.community.clear.ml/projects/945bd0c36255401197336ac56f0c2cc3/experiments/d1d9013b6cd64401899d4b49e2d50e8c/output/log\n",
      "tcmalloc: large alloc 4294967296 bytes == 0x9082000 @  0x7fe8a65d9001 0x7fe8a381c4ff 0x7fe8a386cb08 0x7fe8a3870ac7 0x7fe8a390f1a3 0x50a4a5 0x50cc96 0x507be4 0x508ec2 0x594a01 0x549e8f 0x5515c1 0x5a9dac 0x50a433 0x50cc96 0x507be4 0x588e5c 0x59fd0e 0x50d256 0x507be4 0x588e5c 0x59fd0e 0x50d256 0x507be4 0x588e5c 0x59fd0e 0x50d256 0x5095c8 0x50a2fd 0x50beb4 0x507be4\n",
      "tcmalloc: large alloc 4294967296 bytes == 0x7fe6b5060000 @  0x7fe8a65d71e7 0x7fe8a381c41e 0x7fe8a386cc2b 0x7fe8a386d30f 0x7fe8a390f0a3 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4\n",
      "tcmalloc: large alloc 4294967296 bytes == 0x7fe5b405e000 @  0x7fe8a65d71e7 0x7fe8a381c41e 0x7fe8a386cc2b 0x7fe8a386d30f 0x7fe84f15c0c5 0x7fe84eadf902 0x7fe84eadfeb2 0x7fe84ea98c3e 0x50a12f 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x588c8b 0x59fd0e 0x50d256 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x508ec2 0x594a01\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 1\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"initial_strength\": 0.393,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 10,\n",
      "  \"network_snapshot_ticks\": 30,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"/content/datasets/bonn\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": true\n",
      "  },\n",
      "  \"metric_arg_list\": [],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"/content/datasets/bonn\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 128,\n",
      "    \"mirror_augment\": true\n",
      "  },\n",
      "  \"total_kimg\": 50000,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 32,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"/content/network-snapshot-029610.pkl.pkl\",\n",
      "  \"run_dir\": \"/content/saves/00001-bonn-mirror-auto_tuned1-kimg50000-p0.393-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  /content/saves/00001-bonn-mirror-auto_tuned1-kimg50000-p0.393-resumecustom\n",
      "Training data:     /content/datasets/bonn\n",
      "Training length:   50000 kimg\n",
      "Resolution:        128\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "tcmalloc: large alloc 4294967296 bytes == 0x9082000 @  0x7fe8a65d9001 0x7fe8a381c4ff 0x7fe8a386cb08 0x7fe8a3870ac7 0x7fe8a390f1a3 0x50a4a5 0x50cc96 0x507be4 0x508ec2 0x594a01 0x549e8f 0x5515c1 0x5a9dac 0x50a433 0x50cc96 0x507be4 0x588e5c 0x59fd0e 0x50d256 0x507be4 0x588e5c 0x59fd0e 0x50d256 0x507be4 0x588e5c 0x59fd0e 0x50d256 0x5095c8 0x50a2fd 0x50beb4 0x507be4\n",
      "tcmalloc: large alloc 4294967296 bytes == 0x7fe4a5d72000 @  0x7fe8a65d71e7 0x7fe8a381c41e 0x7fe8a386cc2b 0x7fe8a386d30f 0x7fe8a390f0a3 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4\n",
      "tcmalloc: large alloc 4294967296 bytes == 0x7fe4a5d72000 @  0x7fe8a65d71e7 0x7fe8a381c41e 0x7fe8a386cc2b 0x7fe8a386d30f 0x7fe84f15c0c5 0x7fe84eadf902 0x7fe84eadfeb2 0x7fe84ea98c3e 0x50a12f 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x588c8b 0x59fd0e 0x50d256 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x508ec2 0x594a01\n",
      "Image shape: [3, 128, 128]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n",
      "Resuming from \"/content/network-snapshot-029610.pkl.pkl\"\n",
      "Resuming from kimg = 29610.0\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 12, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 12, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "---                           ---       ---                 ---             \n",
      "Total                         22949277                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 128, 128)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "128x128/FromRGB      512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                23882369                                      \n",
      "\n",
      "Exporting sample images...\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 50000 kimg...\n",
      "\n",
      "tick 0     kimg 29610.1  time 1m 24s       sec/tick 28.3    sec/kimg 220.78  maintenance 55.4   gpumem 8.2   augment 0.394\n",
      "tick 1     kimg 29614.2  time 2m 44s       sec/tick 57.9    sec/kimg 14.13   maintenance 22.2   gpumem 8.3   augment 0.405\n",
      "tick 2     kimg 29618.3  time 3m 42s       sec/tick 58.3    sec/kimg 14.24   maintenance 0.0    gpumem 8.3   augment 0.405\n",
      "tick 3     kimg 29622.4  time 4m 40s       sec/tick 58.2    sec/kimg 14.22   maintenance 0.0    gpumem 8.4   augment 0.412\n",
      "tick 4     kimg 29626.5  time 5m 39s       sec/tick 58.3    sec/kimg 14.23   maintenance 0.0    gpumem 8.4   augment 0.417\n",
      "tick 5     kimg 29630.6  time 6m 37s       sec/tick 58.3    sec/kimg 14.23   maintenance 0.0    gpumem 8.4   augment 0.417\n",
      "tick 6     kimg 29634.7  time 7m 35s       sec/tick 58.3    sec/kimg 14.24   maintenance 0.0    gpumem 8.4   augment 0.428\n",
      "tick 7     kimg 29638.8  time 8m 34s       sec/tick 58.3    sec/kimg 14.23   maintenance 0.0    gpumem 8.4   augment 0.430\n",
      "tick 8     kimg 29642.9  time 9m 32s       sec/tick 58.2    sec/kimg 14.20   maintenance 0.0    gpumem 8.4   augment 0.428\n",
      "tick 9     kimg 29647.0  time 10m 30s      sec/tick 58.2    sec/kimg 14.21   maintenance 0.0    gpumem 8.4   augment 0.425\n",
      "tick 10    kimg 29651.1  time 11m 28s      sec/tick 58.3    sec/kimg 14.24   maintenance 0.0    gpumem 8.4   augment 0.417\n",
      "tick 11    kimg 29655.2  time 12m 39s      sec/tick 58.1    sec/kimg 14.18   maintenance 12.4   gpumem 8.4   augment 0.415\n",
      "tick 12    kimg 29659.3  time 13m 37s      sec/tick 58.1    sec/kimg 14.20   maintenance 0.0    gpumem 8.4   augment 0.417\n",
      "tick 13    kimg 29663.4  time 14m 35s      sec/tick 58.1    sec/kimg 14.17   maintenance 0.0    gpumem 8.4   augment 0.415\n",
      "tick 14    kimg 29667.5  time 15m 33s      sec/tick 58.2    sec/kimg 14.20   maintenance 0.0    gpumem 8.4   augment 0.422\n",
      "tick 15    kimg 29671.6  time 16m 31s      sec/tick 58.0    sec/kimg 14.17   maintenance 0.0    gpumem 8.4   augment 0.415\n",
      "tick 16    kimg 29675.7  time 17m 29s      sec/tick 58.0    sec/kimg 14.17   maintenance 0.0    gpumem 8.4   augment 0.407\n",
      "tick 17    kimg 29679.8  time 18m 27s      sec/tick 58.0    sec/kimg 14.17   maintenance 0.0    gpumem 8.4   augment 0.405\n",
      "tick 18    kimg 29683.9  time 19m 26s      sec/tick 58.0    sec/kimg 14.17   maintenance 0.0    gpumem 8.4   augment 0.407\n",
      "tick 19    kimg 29688.0  time 20m 24s      sec/tick 58.0    sec/kimg 14.16   maintenance 0.0    gpumem 8.4   augment 0.410\n",
      "tick 20    kimg 29692.0  time 21m 22s      sec/tick 58.1    sec/kimg 14.18   maintenance 0.0    gpumem 8.4   augment 0.407\n",
      "tick 21    kimg 29696.1  time 22m 27s      sec/tick 58.1    sec/kimg 14.18   maintenance 7.5    gpumem 8.4   augment 0.415\n",
      "tick 22    kimg 29700.2  time 23m 25s      sec/tick 58.0    sec/kimg 14.17   maintenance 0.0    gpumem 8.4   augment 0.407\n",
      "tick 23    kimg 29704.3  time 24m 23s      sec/tick 58.0    sec/kimg 14.16   maintenance 0.0    gpumem 8.4   augment 0.405\n",
      "tick 24    kimg 29708.4  time 25m 21s      sec/tick 57.9    sec/kimg 14.14   maintenance 0.0    gpumem 8.4   augment 0.405\n",
      "tick 25    kimg 29712.5  time 26m 19s      sec/tick 58.0    sec/kimg 14.16   maintenance 0.0    gpumem 8.4   augment 0.399\n",
      "tick 26    kimg 29716.6  time 27m 17s      sec/tick 58.1    sec/kimg 14.19   maintenance 0.0    gpumem 8.4   augment 0.402\n",
      "tick 27    kimg 29720.7  time 28m 15s      sec/tick 58.0    sec/kimg 14.16   maintenance 0.0    gpumem 8.4   augment 0.394\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "!python stylegan2-ada/train.py \\\n",
    " --outdir='/content/saves' \\\n",
    " --snap=30 \\\n",
    " --im_snap=10 \\\n",
    " --gpus=1 \\\n",
    " --data='/content/datasets/bonn' \\\n",
    " --mirror=true \\\n",
    " --metrics=none \\\n",
    " --resume='/content/network-snapshot-029610.pkl.pkl' \\\n",
    " --kimg=50000 \\\n",
    " --cfg=auto_tuned \\\n",
    " --p=0.393"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "\n",
    "%tensorflow_version 1.x\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 20\n",
    "network_pkl = '/content/network-snapshot-029610.pkl.pkl'\n",
    "out = 'gen/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python stylegan2-ada/generate.py --network={network_pkl} --outdir=out/notrunc0 --trunc=1.0 --seeds=0-{num_images-1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python stylegan2-ada/generate.py --network={network_pkl} --outdir=out/trunc0 --trunc=0.5 --seeds=0-{num_images-1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"/content/network-snapshot-029610.pkl.pkl\"...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n"
     ]
    }
   ],
   "source": [
    "!python stylegan2-ada/generate_video.py --network={network_pkl} --outdir=out/vid_trunc0.3 --trunc=0.3 --seeds=0-{num_images-1} --interpolation_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"/content/network-snapshot-029610.pkl.pkl\"...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n"
     ]
    }
   ],
   "source": [
    "!python stylegan2-ada/generate_video.py --network={network_pkl} --outdir=out/vid_trunc0.5 --trunc=0.5 --seeds=0-{num_images-1} --interpolation_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"/content/network-snapshot-029610.pkl.pkl\"...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n"
     ]
    }
   ],
   "source": [
    "!python stylegan2-ada/generate_video.py --network={network_pkl} --outdir=out/vid_trunc1 --trunc=1 --seeds=0-{num_images-1} --interpolation_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"/content/network-snapshot-029610.pkl.pkl\"...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n",
      "Generating W vectors...\n",
      "Generating images...\n",
      "Generating style-mixed images...\n",
      "Saving images...\n",
      "Saving image grid...\n"
     ]
    }
   ],
   "source": [
    "!python stylegan2-ada/style_mixing.py --network={network_pkl} --outdir=out/mix_trunc1 --trunc=1.0 --rows=1,41,208,322,424,939 --cols=1,41,208,322,424,939"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"/content/network-snapshot-029610.pkl.pkl\"...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n",
      "Generating W vectors...\n",
      "Generating images...\n",
      "Generating style-mixed images...\n",
      "Saving images...\n",
      "Saving image grid...\n"
     ]
    }
   ],
   "source": [
    "!python stylegan2-ada/style_mixing.py --network={network_pkl} --outdir=out/mix_trunc0.5 --trunc=0.5 --rows=1,41,208,322,424,939 --cols=1,41,208,322,424,939"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"/content/network-snapshot-029610.pkl.pkl\"...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n",
      "Generating W vectors...\n",
      "Generating images...\n",
      "Generating style-mixed images...\n",
      "Saving images...\n",
      "Saving image grid...\n"
     ]
    }
   ],
   "source": [
    "!python stylegan2-ada/style_mixing.py --network={network_pkl} --outdir=out/mix_trunc0.3 --trunc=0.3 --rows=1,41,208,322,424,939 --cols=1,41,208,322,424,939"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"/content/network-snapshot-029610.pkl.pkl\"...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n",
      "Generating W vectors...\n",
      "Generating images...\n",
      "Generating style-mixed images...\n",
      "Saving images...\n",
      "Saving image grid...\n"
     ]
    }
   ],
   "source": [
    "!python stylegan2-ada/style_mixing.py --network={network_pkl} --outdir=out/mix1_trunc0.3 --trunc=0.3 --rows=2,42,209,323,425,938 --cols=2,42,209,323,425,938"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"/content/network-snapshot-029610.pkl.pkl\"...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n",
      "Generating W vectors...\n",
      "Generating images...\n",
      "Generating style-mixed images...\n",
      "Saving images...\n",
      "Saving image grid...\n"
     ]
    }
   ],
   "source": [
    "!python stylegan2-ada/style_mixing.py --network={network_pkl} --outdir=out/mix1_trunc0.5 --trunc=0.5 --rows=2,42,209,323,425,938 --cols=2,42,209,323,425,938"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"/content/network-snapshot-029610.pkl.pkl\"...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n",
      "Generating W vectors...\n",
      "Generating images...\n",
      "Generating style-mixed images...\n",
      "Saving images...\n",
      "Saving image grid...\n"
     ]
    }
   ],
   "source": [
    "!python stylegan2-ada/style_mixing.py --network={network_pkl} --outdir=out/mix2_trunc0.3 --trunc=0.3 --rows=3,43,203,324,426,939 --cols=3,43,203,324,426,939"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"/content/network-snapshot-029610.pkl.pkl\"...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n",
      "Generating W vectors...\n",
      "Generating images...\n",
      "Generating style-mixed images...\n",
      "Saving images...\n",
      "Saving image grid...\n"
     ]
    }
   ],
   "source": [
    "!python stylegan2-ada/style_mixing.py --network={network_pkl} --outdir=out/mix2_trunc0.5 --trunc=0.5 --rows=3,43,203,324,426,939 --cols=3,43,203,324,426,939"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"/content/network-snapshot-029610.pkl.pkl\"...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n",
      "Projector: Computing W midpoint and stddev using 10000 samples...\n",
      "Projector: std = 21.0693\n",
      "Projector: Setting up noise inputs...\n",
      "Projector: Building image output graph...\n",
      "Projector: Building loss graph...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/vgg16_zhang_perceptual.pkl ... done\n",
      "Projector: Building noise regularization graph...\n",
      "Projector: Setting up optimizer...\n",
      "Projector: Preparing target images...\n",
      "Projector: Initializing optimization state...\n",
      " 52% 517/1000 [00:38<00:31, 15.21it/s, dist=0.2109, loss=1.67]   "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "ims = os.listdir('/content/projector')\n",
    "\n",
    "for i, im in enumerate(ims):\n",
    "    im_path = os.path.join('projector', im)\n",
    "    \n",
    "    image = Image.open(os.path.join(im_path))\n",
    "    new_image = image.resize((128, 128))\n",
    "    new_image.save(im_path)\n",
    "                       \n",
    "    !python stylegan2-ada/projector.py --network={network_pkl} --outdir=projector/{i + 1} --seed=0 --target={im_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"/content/network-snapshot-029610.pkl.pkl\"...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n"
     ]
    }
   ],
   "source": [
    "!python stylegan2-ada/generate_video_from_latents.py --network={network_pkl} --outdir=out/latents_trunc1 --trunc=1 \\\n",
    "    --dlatents_count=10 \\\n",
    "    --interpolation_size=100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"/content/network-snapshot-029610.pkl.pkl\"...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n"
     ]
    }
   ],
   "source": [
    "!python stylegan2-ada/generate_video_from_latents.py --network={network_pkl} --outdir=out/latents_trunc0.5 --trunc=.5 \\\n",
    "    --dlatents_count=10 \\\n",
    "    --interpolation_size=100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"/content/network-snapshot-029610.pkl.pkl\"...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n"
     ]
    }
   ],
   "source": [
    "!python stylegan2-ada/generate_video_from_latents.py --network={network_pkl} --outdir=out/latents_trunc0.3 --trunc=.3 \\\n",
    "    --dlatents_count=10 \\\n",
    "    --interpolation_size=100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "sbWQ38fBoo4h",
    "g0oZRRs2KO5A",
    "ruo5KFL4yw0j",
    "Aj-3t7dM98dj",
    "iL6_7wnZKo3w",
    "uDtZ9CVSBvkZ",
    "BWxFpc-QkJOH",
    "UEzOo7gtBNvE",
    "imBVQY2bQyFN",
    "lUKiyWY22dzf"
   ],
   "machine_shape": "hm",
   "name": "StyleGAN2-ADA_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
